{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.ensemble import ExtraTreesRegressor, RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import sklearn.model_selection as ms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import re\n",
    "import datetime\n",
    "import sys\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def displayUniqueCount(series):\n",
    "    data = np.unique(series, return_counts=True)\n",
    "    df = pd.DataFrame(\n",
    "        data = {'Valeur':data[0], 'Nombre':data[1]},\n",
    "        columns = ['Valeur', 'Nombre'])\n",
    "    df.sort_values(by =\"Nombre\", ascending=False, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ROOT_DIR = os.getcwd()\n",
    "DATA ='data_challenge'\n",
    "DATA_DIR = os.path.join(ROOT_DIR, DATA)\n",
    "RES ='submit'\n",
    "RES_DIR = os.path.join(ROOT_DIR, RES)\n",
    "TRAIN=\"train\"\n",
    "TEST=\"test\"\n",
    "SOURCE=\"source\"\n",
    "TARGET=\"prix\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv(os.path.join(DATA_DIR, 'boites_medicaments_train.csv'),\n",
    "                    encoding='utf-8',\n",
    "                    sep=';')\n",
    "\n",
    "test = pd.read_csv(os.path.join(DATA_DIR, 'boites_medicaments_test.csv'),\n",
    "                   encoding='utf-8', \n",
    "                   sep=';')\n",
    "\n",
    "train[SOURCE] = TRAIN\n",
    "test[SOURCE] = TEST\n",
    "BIG = pd.concat([train, test], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation des donnees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types de features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DELETE    :   ['libelle', 'id']\n",
      "DUMMY     :   ['statut', 'etat commerc', 'agrement col', 'statut admin', 'type proc', 'forme pharma']\n",
      "ENCODE    :   []\n",
      "TRANSFORM :   ['convertTx', 'log', 'voies_admin', 'substance', 'titulaire', 'new_libelle']\n"
     ]
    }
   ],
   "source": [
    "# features numériques\n",
    "feat_num = ['libelle_plaquette', 'libelle_ampoule', 'libelle_flacon', \n",
    "            'libelle_tube', 'libelle_stylo', 'libelle_seringue',\n",
    "            'libelle_pilulier', 'libelle_sachet', 'libelle_comprime', \n",
    "            'libelle_gelule', 'libelle_film', 'libelle_poche',\n",
    "            'libelle_capsule'] + ['nb_plaquette', 'nb_ampoule', \n",
    "            'nb_flacon', 'nb_tube', 'nb_stylo', 'nb_seringue',\n",
    "            'nb_pilulier', 'nb_sachet', 'nb_comprime', 'nb_gelule', \n",
    "            'nb_film', 'nb_poche', 'nb_capsule', 'nb_ml']\n",
    "# features date\n",
    "feat_dates = ['date declar annee', 'date amm annee']\n",
    "# features catégorielles\n",
    "feat_cat = ['statut', 'etat commerc', 'agrement col', 'tx rembours',\n",
    "           'statut admin', 'type proc']\n",
    "# features texte\n",
    "feat_text = ['libelle', 'titulaires', 'substances', 'forme pharma', 'voies admin']\n",
    "\n",
    "\n",
    "featToDel = ['libelle', 'id'] #,'voies admin_NB','substances_NB'\n",
    "featToDummy = feat_cat\n",
    "featToDummy.remove('tx rembours')\n",
    "featToDummy.extend(['forme pharma'])\n",
    "featToEncode = []\n",
    "featToTransform = [ \"convertTx\", \"log\", \"voies_admin\", \"substance\", \"titulaire\", \"new_libelle\"] #, \"gboost\", \"ensemble\", \"new_libelle\", \"ensemble\",\"buildBIG\", \n",
    "\n",
    "config = {\"featToDel\":featToDel,\n",
    "          \"featToDummy\":featToDummy,\n",
    "          \"featToEncode\":featToEncode,\n",
    "          \"featToTransform\":featToTransform}\n",
    "\n",
    "print \"DELETE    :  \", featToDel\n",
    "print \"DUMMY     :  \", featToDummy\n",
    "print \"ENCODE    :  \", featToEncode\n",
    "print \"TRANSFORM :  \", featToTransform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering : LIBELLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def addNBLibelle(val, X):\n",
    "    regexp = re.compile(\"([0-9]{1,5})\\s\" + val + \"*\")\n",
    "    X[\"nb_\" + val] = X.libelle.apply(lambda w : regexp.search(w).group(1) if regexp.search(w) else 0)\n",
    "    X[\"libelle_\" + val] = X.libelle.apply(lambda w : 1 if regexp.search(w) else 0)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering : SUBSTANCES - VOIES ADMIN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Création du Bag of words substances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_column(X, name):\n",
    "\n",
    "    distinctCategs = (X[name]\n",
    "                      .apply(lambda col_value : col_value.split(','))\n",
    "                      .apply(pd.Series)\n",
    "                      .unstack()\n",
    "                      .dropna()\n",
    "                      .str.strip()\n",
    "                      .unique())\n",
    "\n",
    "    #pd.DataFrame(distinctCategs).to_csv(\"distinctCateg\"+name +\".csv\", encoding=\"utf-8\", sep=\";\")\n",
    "    \n",
    "    for distinctCateg in distinctCategs:\n",
    "        X[distinctCateg] = X[name].apply(lambda x : 1 if distinctCateg in x else 0)\n",
    "        \n",
    "    X[name + \"_NB\"] = X[distinctCategs].sum(axis=1)\n",
    "    \n",
    "    print \"Add \" + str(len(distinctCategs)) + \" new columns\"\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering : SUBSTANCES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def transfo_substances(X, index):\n",
    "\n",
    "    X = (X\n",
    "         .apply(lambda subs: re.sub(r'(\\([^)]*\\))','', subs))\n",
    "         .apply(lambda subs: subs.replace(\"é\",\"e\"))\n",
    "         .apply(lambda subs: subs.replace(\"es\",\"e\"))\n",
    "         .apply(lambda subs: subs.replace(\"ee\",\"e\"))\n",
    "         .apply(lambda subs: subs.replace(\"-\",\"\"))\n",
    "         .apply(lambda subs: subs.replace(\"doxyxycline\", \"doxycycline\"))\n",
    "         .apply(lambda subs: subs.replace(\"alpha\", \"alfa\")))\n",
    "    \n",
    "    stop_words={\"d\", \"de\", \"des\",\"du\",\"à\",\"10a\",\"11\",\"11a\",\"12f\",\"1331\",\"135\",\"13c\",\"14\",\"158\",\"15b\",\"16\",\"165\",\"175\",\"179a\",\n",
    "            \"17f\",\"18\",\"181\",\"18c\",\"197\",\"19a\",\"19f\",\"1a\",\"1b\",\"20\",\"2009\",\"2010\",\"2011\",\"2013\",\"2014\",\"22f\",\"23f\",\"27\",\"2a\",\n",
    "            \"2b\",\"3073\",\"326f\",\"3350\",\"33f\",\"361\",\"39\",\"4000\",\"4385\",\"55\",\"6a\",\"6b\",\"74xp\",\"7f\",\"88\",\"940\",\"9715293\",\n",
    "            \"974p\",\"980\",\"9n\",\"9v\", \"extrait\",\"allergenique\", \"humaine\", \"recombinante\", \"conjuguee\", \"la\", \"extrait\",\n",
    "            \"fruit\", \"proteine\", \"vectrice\", \"des\",\"en\", \"gel\",\"gomme\",\"venin\", \"proteine\", \"recombinante\", \"adsorbee\",\n",
    "            \"virus\", \"humain\", \"hpv\", \"type\", \"proteines\", \"pre\", \"purifiee\", \"souche\", \"ra\", \"vivant\", \"riche\", \"sec\",\n",
    "            \"ab\", \"et\", \"polyoside\", \"serotypes\", \"conjugues\",\"vectrice\",\"attendue\",\"utilisee\", \"synthetique\", \"oxyde\", \n",
    "            \"base\", \"acide\",\"acides\", \"actif\",\"active\", \"adjuvant\", \"adsorbe\", \"afrique\",\"ecorce\", \"mou\", \"fusion\",\n",
    "            \"groupe\", \"chaine\", \"agglomere\", \"cire\", \"element\", \"especes\", \"excipient\", \"externe\", \"forme\", \"glacial\", \n",
    "            \"leger\", \"lourd\", \"chlorhydrate\", \"sodique\",\"hydrochlorothiazide\",\"anhydre\"}\n",
    "\n",
    "    vectorizer = CountVectorizer(min_df=0., max_df=1.0, stop_words=stop_words, strip_accents=\"ascii\")\n",
    "    SUBS_VECT = vectorizer.fit_transform(X)\n",
    "    feat_names = vectorizer.get_feature_names()\n",
    "\n",
    "    return pd.DataFrame(data=SUBS_VECT.A, columns=feat_names, index= index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des features catégorielles\n",
    "\n",
    "Les algorithmes de machine learning s'attendent à avoir en entrée des nombres, et non pas des chaînes de caractères. C'est pourquoi nous transformons les features catégorielles en nombres, à l'aide de LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def parse(X, config, silent=False) :\n",
    "    start = datetime.datetime.today().now()\n",
    "    if not silent:\n",
    "        print '__________________________________________ PARSE __________________________________________'\n",
    "        print '--> ', start.strftime('%d-%m-%Y : %H:%M')\n",
    "        print 'BEFORE : ', X.shape\n",
    "    \n",
    "    if \"titulaire\" in config[\"featToTransform\"]:\n",
    "        print \"Get titulaire first word\"\n",
    "        X[\"titulaires\"] = (X[\"titulaires\"]\n",
    "                      .apply(lambda col_value : col_value.replace('LABORATOIRES',''))\n",
    "                      .apply(lambda col_value : col_value.replace('BRISTOL-MYERS',' BRISTOL MYERS'))\n",
    "                      .apply(lambda col_value : col_value.replace('SANOFI-AVENTIS','SANOFI AVENTIS'))\n",
    "                      .str.strip()\n",
    "                      .apply(lambda titulaire : titulaire.split(' ')[0] )\n",
    "                      .apply(pd.Series))\n",
    "        config[\"featToEncode\"].extend(['titulaires'])\n",
    "\n",
    "    if \"substance\" in config[\"featToTransform\"]:\n",
    "        print \"Create a Substance column for each substance\"\n",
    "        X[\"substances\"] = (X[\"substances\"]\n",
    "                           .apply(lambda subs: re.sub(r'(\\([^)]*\\))','', subs))\n",
    "                           .apply(lambda subs: subs.replace(\"es\",\"e\"))\n",
    "                           .apply(lambda subs: subs.replace(\"ee\",\"e\"))\n",
    "                           .apply(lambda subs: subs.replace(\"doxyxycline\", \"doxycycline\"))\n",
    "                           .apply(lambda subs: subs.replace(\"alpha\", \"alfa\")))\n",
    "        X = create_column(X, \"substances\")\n",
    "        X.drop(\"substances\", axis =1, inplace=True)\n",
    "    \n",
    "    if \"voies_admin\" in config[\"featToTransform\"]:\n",
    "        print \"Create a Voie Admin column for each voie admin\"\n",
    "        X = create_column(X, \"voies admin\")\n",
    "        X.drop(\"voies admin\", axis =1, inplace=True)\n",
    "        \n",
    "    if \"convertTx\" in config[\"featToTransform\"]:\n",
    "        print \"convert tx rembours\"\n",
    "        X[\"tx rembours\"] = [int(x.replace(\"%\", \"\")) for x in X[\"tx rembours\"]]\n",
    "        \n",
    "    if \"new_libelle\" in config[\"featToTransform\"]:\n",
    "        lib_to_add = [\"cartouche\",\"bouteille\",\"film\",\"inhalateur\", \"PEHD\"]\n",
    "        for lib in lib_to_add:\n",
    "            X = addNBLibelle(lib, X)\n",
    "            \n",
    "    if \"drop_duplicates\" in config[\"featToTransform\"]:\n",
    "        X.drop_duplicates(inplace=True)\n",
    "        \n",
    "    if \"gboost\"in config[\"featToTransform\"]:\n",
    "        RESULTAT = pd.read_csv(os.path.join(RES_DIR, 'predX15.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_15 = pd.read_csv(os.path.join(RES_DIR, 'soumission15.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        X['SUB_BOOST'] = pd.concat([RESULTAT.prix, SUB_15.prix],axis=0)\n",
    "        \n",
    "    if \"ensemble\" in config[\"featToTransform\"]:\n",
    "        RESULTAT = pd.read_csv(os.path.join(RES_DIR, 'resultat.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_1 = pd.read_csv(os.path.join(RES_DIR, 'soumission1.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_1.rename(index=str, columns={\"prix\": \"SUB_1\"}, inplace=True)\n",
    "        SUB_4 = pd.read_csv(os.path.join(RES_DIR, 'soumission4.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_4.rename(index=str, columns={\"prix\": \"SUB_4\"}, inplace=True)\n",
    "        SUB_9 = pd.read_csv(os.path.join(RES_DIR, 'soumission9.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_9.rename(index=str, columns={\"prix\": \"SUB_9\"}, inplace=True)\n",
    "        SUB_11 = pd.read_csv(os.path.join(RES_DIR, 'soumission11.csv'),\n",
    "                            encoding='utf-8',\n",
    "                            sep=';')\n",
    "        SUB_11.rename(index=str, columns={\"prix\": \"SUB_11\"}, inplace=True)\n",
    "        SUB = pd.concat([SUB_1.SUB_1, SUB_4.SUB_4, SUB_9.SUB_9, SUB_11.SUB_11],axis=1)\n",
    "\n",
    "        RESULTAT_ENS = pd.concat([RESULTAT, SUB],axis=0)\n",
    "        BIG['SUB_1']=RESULTAT_ENS['SUB_1']\n",
    "        BIG['SUB_4']=RESULTAT_ENS['SUB_4']\n",
    "        BIG['SUB_9']=RESULTAT_ENS['SUB_9']\n",
    "        BIG['SUB_11']=RESULTAT_ENS['SUB_11']\n",
    "\n",
    "    #remove target\n",
    "    y_train = X.loc[X.source == 'train',TARGET]\n",
    "    \n",
    "    if \"log\" in config[\"featToTransform\"]:\n",
    "        y_train = y_train.apply(np.log1p)\n",
    "                    \n",
    "    del X[TARGET]\n",
    "    \n",
    "    print \"---Feature to encode \"\n",
    "    #Feature to encode\n",
    "    featToEncode = config[\"featToEncode\"]\n",
    "    for encodeToCat in featToEncode:\n",
    "        print \"encode \" + encodeToCat\n",
    "        le = LabelEncoder()\n",
    "        le.fit(X[encodeToCat])\n",
    "        X.loc[:,encodeToCat] = le.transform(X[encodeToCat])\n",
    "    \n",
    "    print \"---Feature to dummy \"\n",
    "    #Feature to dummy\n",
    "    featToDummy = config[\"featToDummy\"]\n",
    "    print featToDummy\n",
    "    if featToDummy:\n",
    "        dums = pd.get_dummies(X[featToDummy]).astype(int)\n",
    "        X = pd.concat([X, dums], axis=1)\n",
    "        X.drop(featToDummy, axis =1, inplace=True)\n",
    "    \n",
    "    print \"---Feature to delete \"\n",
    "    #Feature to delete\n",
    "    featToDel = config[\"featToDel\"]\n",
    "    X.drop(featToDel, axis =1, inplace=True)\n",
    "    \n",
    "    if \"buildBIG\" in config[\"featToTransform\"]:\n",
    "        print \"---Build BIG.csv \" \n",
    "        X.to_csv(DATA_DIR + '/'+ 'BIG.csv', header=True, index=False,sep=';', encoding='utf-8')\n",
    "    \n",
    "    X_train = X[X[SOURCE] == TRAIN]\n",
    "    X_test = X[X[SOURCE] == TEST]    \n",
    "    del X_test[SOURCE]\n",
    "    del X_train[SOURCE]\n",
    "    \n",
    "    \n",
    "    if not silent:\n",
    "        print '%s Elapsed time :%d s' % (datetime.datetime.today().now().strftime('--> %d-%m-%Y : %H:%M'), \n",
    "        (datetime.datetime.today().now().now() - start).total_seconds())\n",
    "        print 'AFTER TRAIN :', X_train.shape\n",
    "        print 'AFTER TEST :', X_test.shape\n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    return X_train, X_test, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________ PARSE __________________________________________\n",
      "-->  31-10-2016 : 20:21\n",
      "BEFORE :  (12235, 43)\n",
      "Get titulaire first word\n",
      "Create a Substance column for each substance\n",
      "Add 1739 new columns\n",
      "Create a Voie Admin column for each voie admin\n",
      "Add 45 new columns\n",
      "convert tx rembours\n",
      "---Feature to encode \n",
      "encode titulaires\n",
      "---Feature to dummy \n",
      "['statut', 'etat commerc', 'agrement col', 'statut admin', 'type proc', 'forme pharma']\n",
      "---Feature to delete \n",
      "--> 31-10-2016 : 20:22 Elapsed time :22 s\n",
      "AFTER TRAIN : (8564, 2061)\n",
      "AFTER TEST : (3671, 2061)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train = parse(BIG.copy(), config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creation d'un modele"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métrique MAPE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Mean Absolute Percentage Error\n",
    "def mape_error(y_true, y_pred): \n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def crossVal (X, y, clf, scorer, n_splits=10, shuffle = False) :\n",
    "    folds= ms.KFold(n_splits=n_splits, shuffle= shuffle, random_state=None) #shuffle = False, random_state\n",
    "    # When shuffle=True, pseudo-random number generator state used for shuffling.\n",
    "    # If None, use default numpy RNG for shuffling\n",
    "    scoreList = []\n",
    "    i = 0\n",
    "    for trainIdx, testIdx in folds.split(X):\n",
    "        i +=1 \n",
    "        XTrainFolds = None; XTestFolds = None; yTrainFolds= None; yTestFolds= None\n",
    "        yPred = []\n",
    "        XTrainFolds, XTestFolds = X.iloc[trainIdx], X.iloc[testIdx]\n",
    "        yTrainFolds, yTestFolds = y.iloc[trainIdx], y.iloc[testIdx]\n",
    "        clf = clf.fit(XTrainFolds, yTrainFolds)\n",
    "        res = clf.predict(XTestFolds)\n",
    "        \n",
    "        if \"log\" in config[\"featToTransform\"]:\n",
    "            score = scorer(np.expm1(yTestFolds), np.expm1(res))\n",
    "        else:\n",
    "            score = scorer(yTestFolds, res)\n",
    "        scoreList.append(score)\n",
    "        print \"*** MAPE Error : \" + str(i) + \" - \" + str(score)\n",
    "        sys.stdout.flush()\n",
    "        \n",
    "    print \"----------------\"\n",
    "    print \"  - Mean :\" + str(np.mean(scoreList))\n",
    "    print \"  - Ecart Max-Min :\" + str(np.max(scoreList) - np.min(scoreList))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GradientBoostingRegressor(n_estimators=500, loss='huber', alpha=0.23, max_depth=80, max_leaf_nodes=100, random_state=3, min_samples_split=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "crossVal(X_train, y_train, clf, mape_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calcul des predictions et soumission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           0.1830           44.32m\n",
      "         2           0.1604           44.73m\n",
      "         3           0.1333           44.81m\n",
      "         4           0.1164           45.72m\n",
      "         5           0.1025           45.28m\n",
      "         6           0.0904           44.89m\n",
      "         7           0.0783           44.78m\n",
      "         8           0.0683           44.60m\n",
      "         9           0.0607           45.25m\n",
      "        10           0.0541           45.15m\n",
      "        20           0.0204           46.75m\n",
      "        30           0.0105           47.18m\n",
      "        40           0.0068           46.50m\n",
      "        50           0.0048           45.09m\n",
      "        60           0.0038           43.21m\n",
      "        70           0.0031           68.17m\n",
      "        80           0.0025           62.41m\n",
      "        90           0.0022           58.14m\n",
      "       100           0.0019           53.73m\n",
      "       200           0.0007           30.93m\n",
      "       300           0.0004           21.69m\n",
      "       400           0.0002            9.66m\n",
      "       500           0.0001            0.00s\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)\n",
    "\n",
    "predXtrain = clf.predict(X_train)\n",
    "\n",
    "predictions = clf.predict(X_test)\n",
    "if \"log\" in config[\"featToTransform\"]:\n",
    "    predictions = np.expm1(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(predictions, index=test['id']).to_csv('submit/soumission19.csv',  \n",
    "                          header=['prix'],\n",
    "                          sep = ';', \n",
    "                          dtypes={'id':'int','prix':'int'})"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
